---
title: 这就是搜索引擎（核心技术详解）
date: 2017-12-9 16:00
tags: [搜索引擎,信息检索,张俊林,读书笔记,算法]
---


＃ 这就是搜索引擎：核心技术详解(张俊林)


## 搜索引擎及其技术架构
*产生背景: 随着上世纪互联网技术的的快速发展，个人电脑的数量急剧增加，同时WEB技术的出现,internet成为人们获取信息的主要载体，各种web站点从而急剧增加，如何从纷繁的互联网信息中快速有效的获取人们所需要的信息成为一个重要的问题，而搜索引擎的出现恰恰解决了这个问题。同时搜索引擎也成为人们网上冲浪的重要的入口。
* 发展历程:分类目录(人工)　　－》　　文本检索(简单文本匹配)　　－》　　链接分析(排序)　　　－》　　　用户中心(个性化)
* 搜索引擎三个目标:更全，更快，更准；为了这三个目标，引入了索引，索引压缩，排序，链接分析，反作弊，用户研究，云存储，爬虫，网页去重，缓存等技术；
* 搜索引擎的３个核心问题(不同发展时期关心的侧重不同):
    * (分析)用户真正需求:不同用户，不同场景，不同时空，相同的搜索词对应的真正意图不同；
    * (匹配)那些信息和用户相关:信息检索模型，相关性计算，关键词匹配，自然语言理解
    * (过滤)哪些信息用户可信赖：反作弊，结果排序
* 搜索引擎架构(获取存储海量信息/快速响应用户查询):
    * 收集阶段
        * 网络爬虫获取网页信息，经过去重模块去重
        * 搜索引擎进行网页解析，抽出主体内容，将建立的(倒排)索引存储结构，和链接关系保存在云存储平台；
    * 响应阶段:
        * 查询分析对搜索词进行分析，相关性匹配找到相关内容，链接分析等对其进行排序；
        * 此外还有缓存系统用来加快响应的速度
    * 此外还有反作弊系统等用来提高用户体验
## 网络爬虫
* 通用爬虫框架:
    * 待抓取URL队列(初始为种子URL),
    * 网页下载器:根据待抓取URL下载网页，并存入网页库，并额外维护一个已抓取URL队列(避免重复抓取)
    * URL抽取已网页网页中的URL链接信息，放入待抓取URL队列
* 爬虫系统分类
    * 批量型爬虫:有明确抓取范围:如网页数量，抓取时间等
    * 增量型爬虫:持续不断抓取，并定期更新已抓取的网页
    * 垂直型爬虫:关注特定主题内容:需要分析网页主题，进行筛选
* 优秀爬虫特性：高性能，可扩展性，健壮性，友好性(爬虫禁抓协议)
* 爬虫质量评价标准:覆盖率，时新性，网页重要性
* 抓取策略:待抓取URL队列的排序
    * 宽度优先遍历:即将已抓取网页的URL链接依次放入待抓取URL队列的尾部(包含一定的重要性排序，一般较为重要的网页会先被发现)
    * 反完全PageRank策略:根据已抓取的部分网页进行pagerank排序(效果不佳)，通常当新下载的网页达到一定数量，遍历所有的待抓取URL进行pagerank排序，在间隔期间对于新加入的URL赋予一个临时的pagerank值(所有入链的pangerank值累积)
    * OCIP策略(online page importance computation):可视为改进的pagerank算法，初始时每个网页有相同的"现金"，然后抓取后将自身的"现金"均分给所有的出链，自身清空。然后根据URL的“现金”多少进行排序
    * 大站优先策略:根据URL所属网站分类，那个网站等待下载的页面最多则优先
* 网页更新策略:
    * 历史参考策略:参考该网页的历史更新情况，进行泊松过程建模预测
    * 用户体验策略:保存网页多个历史版本，根据过去每次网页内容更新对搜索质量的影响，作为优先更新的参考依据
    * 聚类抽样策略:根据网页的某些属性对网页进行聚类，从每个类别中抽取几个最具代表性网页的并计算其更新周期，并作为此类别所有网页的更新周期(解决新网页的更新周期冷启动问题)
* 暗网抓取:指常规抓取方式无法抓取到的页面(如一些网站的根据用户输入内容(条件)返回的结果页面)
    * 查询组合问题:对于一个结果页面，条件的组合方式可能多种多样
        *　富含信息查询模板:对于某个查询模板的所有属性均赋值，形成不同的查询组合，提交得到结果页面，若结果网页的内容差异性较大，则这是一个富含信息模板；
        * ISIT算法:首先从一维模板开始，逐个分析，然后扩展到二维，逐步增加维度
    * 文本框填写问题:首先根据人工初始化的种子关键词词表，向垂直搜索引擎提交查询，然后从返回的网页中抽取关键词加入词表，以此递归迭代进行
* 分布式爬虫:
    * 可分为不同层级:如分布式数据中心，分布式抓取服务器，分布式爬虫程序，整个爬虫系统由分布式在各地的数据中心组成，每个数据中心负责抓取本区域的网页，每个数据中心又包含多个抓取服务器，每个抓取服务器可部署多个爬虫程序。
    * 主从式分布爬虫:一台主服务器专门对其他从服务器提供URL分发服务(维护待抓取URL队列，并从网页中获取待抓取URL,则外还负责负载均衡等全局服务)，从服务器则负责实际网页抓取下载
    * 对等式分布爬虫:由服务器自己判断某个网页是否应该自己抓取(根据对URL哈希取模，一致性哈希等方法)    